{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão de Negócio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Questão de Negócio\n",
    "# # Defina claramente a questão que deseja responder com os dados, como identificar clientes insatisfeitos.\n",
    "# # Definir e identificar clientes satisfeitos ou insatisfeitos.\n",
    "\n",
    "# # Entendimento de Negócio\n",
    "# # Realizar análise detalhada do negócio, entendendo as necessidades e requisitos para a classificação de satisfação dos clientes.\n",
    "\n",
    "# # Coleta de dados\n",
    "# # Carregar os dados dos clientes de uma planilha ou fonte de dados.\n",
    "# dados_clientes = pd.read_csv('dataset/tra')\n",
    "\n",
    "# # Limpeza de dados\n",
    "# # Realizar a limpeza dos dados, tratando valores ausentes, removendo duplicatas ou corrigindo erros.\n",
    "# dados_clientes = dados_clientes.dropna()\n",
    "# dados_clientes = dados_clientes.drop_duplicates()\n",
    "\n",
    "# # Exploração de dados\n",
    "# # Analisar os dados e explorar as informações relevantes para entender os padrões e características dos clientes.\n",
    "# # Exemplo de exploração: verificar a distribuição de satisfação dos clientes\n",
    "# satisfacao_counts = dados_clientes['Satisfacao'].value_counts()\n",
    "# print(satisfacao_counts)\n",
    "\n",
    "# # Modelagem de dados\n",
    "# # Preparar os dados para modelagem, dividindo-os em atributos de entrada (X) e variável alvo (y).\n",
    "# X = dados_clientes.drop('Satisfacao', axis=1)\n",
    "# y = dados_clientes['Satisfacao']\n",
    "\n",
    "# # Dividir os dados em conjuntos de treinamento e teste\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Aplicação dos algoritmos de ML\n",
    "# # Escolher e aplicar um algoritmo de aprendizado de máquina, como regressão logística.\n",
    "# modelo = LogisticRegression()\n",
    "# modelo.fit(X_train, y_train)\n",
    "\n",
    "# # Avaliação de performance dos algoritmos\n",
    "# # Avaliar o desempenho do modelo utilizando métricas, como acurácia.\n",
    "# y_pred = modelo.predict(X_test)\n",
    "# acuracia = accuracy_score(y_test, y_pred)\n",
    "# print(\"Acurácia do modelo:\", acuracia)\n",
    "\n",
    "# # Publicação do modelo em Produção\n",
    "# # Utilizar o modelo treinado para prever a satisfação de novos clientes em produção.\n",
    "# novo_cliente = pd.DataFrame([[...]])  # Dados do novo cliente\n",
    "# satisfacao_pred = modelo.predict(novo_cliente)\n",
    "# print(\"Previsão de satisfação:\", satisfacao_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ciclo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base em todas as informações fornecidas, aqui está uma possível abordagem para resolver o problema de satisfação do cliente da InStyle, utilizando as etapas de um projeto de dados:\n",
    "\n",
    "Questão de Negócio:\n",
    "Identificar clientes satisfeitos e insatisfeitos para melhorar a experiência do cliente e aumentar a taxa de satisfação.\n",
    "Entendimento de Negócio:\n",
    "Analisar os desafios enfrentados pela InStyle, como dificuldade em determinar as necessidades dos clientes, problemas de marketing e desenvolvimento, além de quedas do sistema. Identificar a importância da medição da satisfação do cliente para a reputação da empresa.\n",
    "Coleta de dados:\n",
    "Carregar os dados relevantes da InStyle, como informações dos clientes, histórico de compras, feedbacks e reclamações, em um DataFrame a partir dos arquivos CSV fornecidos (train.csv e test.csv).\n",
    "Limpeza de dados:\n",
    "Realizar a limpeza dos dados, tratando valores ausentes, removendo duplicatas e corrigindo erros, se necessário. Garantir que os dados estejam prontos para a análise e modelagem.\n",
    "Exploração de dados:\n",
    "Analisar os dados, realizar estatísticas descritivas e visualizações para entender a distribuição, padrões e relações entre as variáveis. Identificar insights relevantes sobre a satisfação do cliente e possíveis fatores influentes.\n",
    "Modelagem de dados:\n",
    "Preparar os dados para a modelagem, dividindo-os em conjuntos de treinamento (train.csv) e teste (test.csv). Definir os atributos de entrada (X) e a variável alvo (y).\n",
    "Aplicação dos algoritmos de ML:\n",
    "Escolher um algoritmo de aprendizado de máquina adequado, como regressão logística, árvore de decisão ou Random Forest. Treinar o modelo utilizando os dados de treinamento, ajustando-o aos padrões identificados nos dados.\n",
    "Avaliação de performance dos algoritmos:\n",
    "Avaliar o desempenho do modelo utilizando métricas apropriadas, como acurácia, precisão, recall ou F1-score. Utilizar os dados de teste para avaliar a capacidade do modelo em generalizar em dados não vistos anteriormente.\n",
    "Publicação do modelo em Produção:\n",
    "Implantar o modelo treinado em produção, permitindo que seja usado para prever a satisfação de novos clientes. Por exemplo, fornecer informações de um novo cliente ao modelo e obter uma previsão de sua satisfação.\n",
    "Essa abordagem abrange todas as etapas importantes de um projeto de dados, desde a compreensão do problema de negócio até a publicação do modelo em produção. Lembre-se de personalizar e ajustar o código de acordo com as características específicas dos dados e dos algoritmos escolhidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'snb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 18\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# import matplotlib.pyplot as plt\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# from sklearn.model_selection import train_test_split\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# from sklearn.linear_model import LogisticRegression\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# from sklearn.metrics import accuracy_score\u001b[39;00m\n\u001b[1;32m     17\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[43msnb\u001b[49m\u001b[38;5;241m.\u001b[39mset_style(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhitegrid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'snb' is not defined"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sweetviz as sv\n",
    "\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "snb.set_style('whitegrid')\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dtypes(df):\n",
    "    print(df.dtypes)\n",
    "    return None\n",
    "\n",
    "def show_dimensions(df):\n",
    "    print('Number of rows: {}' .format(df.shape[0]))\n",
    "    print('Number of columns: {}' .format(df.shape[1]))\n",
    "    return None\n",
    "\n",
    "def cramer_v( x, y ):\n",
    "    cm = pd.crosstab( x, y ).to_numpy()\n",
    "    n = cm.sum()\n",
    "    r, k = cm.shape\n",
    "    \n",
    "    chi2 = stats.chi2_contingency( cm )[0]\n",
    "    chi2corr = max( 0, chi2 - (k-1)*(r-1)/(n-1) )\n",
    "    \n",
    "    kcorr = k - (k-1)**2/(n-1)\n",
    "    rcorr = r - (r-1)**2/(n-1)\n",
    "    return round(np.sqrt( (chi2corr/n) / ( min( kcorr-1, rcorr-1 ) ) ),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coleta de dados\n",
    "# Carregar os dados de treinamento e teste a partir dos arquivos CSV\n",
    "df_train = pd.read_csv('dataset/train.csv')\n",
    "df_teste = pd.read_csv('dataset/test.csv')\n",
    "sub_m = pd.read_csv('dataset/submission.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data descrip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando as estatísticas básicas do conjunto de dados\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter informações gerais sobre o dataframe, Algumas variáveis são numéricas, enquanto outras são categóricas.\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para visualizar a distribuição das variáveis numéricas, podemos utilizar o histograma\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10,10]\n",
    "num_attributes = df.select_dtypes( include= ['float64', 'int64'] )\n",
    "num_attributes.hist( bins= 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.rename(columns={'id', 'Gender', 'Customer Type', 'Age', 'Type of Purchase',\n",
    "#        'Store size', 'Store distance', 'InStore wifi',\n",
    "#        'Open/Close time convenient', 'Easy of online shopping',\n",
    "#        'Store location', 'Toilet cleaning', 'Dressing room', 'Waiting room',\n",
    "#        'Kids entertainment', 'Seller service', 'Showroom ', 'Self-Store',\n",
    "#        'Purchase service', 'Store Service', 'Cleanliness',\n",
    "#        'Carrier delay in minutes', 'Delivery delay in minutes',\n",
    "#        'Satisfaction'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando o tamanho do conjunto de dados\n",
    "show_dimensions(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dtypes(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Check NaN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a presença de valores nulos\n",
    "df.isna().sum()#/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill drop Na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dropna(inplace=True)\n",
    "df['Delivery delay in minutes'] = df['Delivery delay in minutes'].apply(\n",
    "    lambda x: 'nao_identificado' if pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores duplicados\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Delivery delay in minutes'] = df['Delivery delay in minutes'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Data Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[''].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sweetviz as sv\n",
    "\n",
    "# # Carregue seus dados em um DataFrame (df1)\n",
    "\n",
    "# # Gere o relatório de análise exploratória\n",
    "# report = sv.analyze(df1)\n",
    "\n",
    "# # Visualize o relatório no navegador\n",
    "# report.show_html('report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "# Plotando o gráfico de barras com a contagem\n",
    "ax = sns.countplot(x=\"hotel_rating\",\n",
    "                   hue=\"tourism_agency_booking\", data=df1)\n",
    "\n",
    "# Adicionando o valor da contagem em cima de cada barra\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x()+p.get_width()/2., height+3,\n",
    "            '{:.0f}'.format(height), ha=\"center\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Variables\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "num_attributes = df1.select_dtypes(include=['int64', 'float64'])\n",
    "corr = num_attributes.corr(method='pearson')\n",
    "sns.heatmap(corr, annot=True, fmt='.2f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Variables\n",
    "plt.rcParams['figure.figsize'] = [8,8]\n",
    "cat_attributes = df1.select_dtypes(include='object')\n",
    "lista=[]\n",
    "for col in cat_attributes.columns:\n",
    "    lista2 =[]\n",
    "    for col2 in cat_attributes.columns:\n",
    "        lista2.append(cramer_v(cat_attributes[col], cat_attributes[col2]))\n",
    "    lista.append(lista2)\n",
    "cramer = pd.DataFrame(lista,columns=cat_attributes.columns,index=cat_attributes.columns)\n",
    "sns.heatmap(cramer,annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Variables\n",
    "plt.rcParams['figure.figsize'] = [8,8]\n",
    "cat_attributes = df1.select_dtypes(include='object')\n",
    "lista=[]\n",
    "for col in cat_attributes.columns:\n",
    "    lista2 =[]\n",
    "    for col2 in cat_attributes.columns:\n",
    "        lista2.append(cramer_v(cat_attributes[col], cat_attributes[col2]))\n",
    "    lista.append(lista2)\n",
    "cramer = pd.DataFrame(lista,columns=cat_attributes.columns,index=cat_attributes.columns)\n",
    "sns.heatmap(cramer,annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103904, 24)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dados' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Limpeza de dados (opcional)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Se necessário, realizar a limpeza dos dados de treinamento e teste\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m dados \u001b[38;5;241m=\u001b[39m \u001b[43mdados\u001b[49m\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m      4\u001b[0m dados \u001b[38;5;241m=\u001b[39m dados\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dados' is not defined"
     ]
    }
   ],
   "source": [
    "# Limpeza de dados (opcional)\n",
    "# Se necessário, realizar a limpeza dos dados de treinamento e teste\n",
    "dados = dados.dropna()\n",
    "dados = dados.drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelagem de dados\n",
    "# Preparar os dados para modelagem, dividindo-os em atributos de entrada (X) e variável alvo (y)\n",
    "X_treinamento = dados_treinamento.drop('Satisfacao', axis=1)\n",
    "y_treinamento = dados_treinamento['Satisfacao']\n",
    "X_teste = dados_teste.drop('Satisfacao', axis=1)\n",
    "y_teste = dados_teste['Satisfacao']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicação dos algoritmos de ML\n",
    "# Escolher e aplicar um algoritmo de aprendizado de máquina, como regressão logística\n",
    "modelo = LogisticRegression()\n",
    "modelo.fit(X_treinamento, y_treinamento)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação de performance dos algoritmos\n",
    "# Avaliar o desempenho do modelo utilizando métricas, como acurácia\n",
    "y_pred = modelo.predict(X_teste)\n",
    "acuracia = accuracy_score(y_teste, y_pred)\n",
    "print(\"Acurácia do modelo:\", acuracia)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publicação do modelo em Produção\n",
    "# Utilizar o modelo treinado para prever a satisfação de novos clientes em produção\n",
    "novo_cliente = pd.DataFrame([[...]])  # Dados do novo cliente\n",
    "satisfacao_pred = modelo.predict(novo_cliente)\n",
    "print(\"Previsão de satisfação:\", satisfacao_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entendimento de Negócio\n",
    "# Faça uma análise detalhada do negócio, entenda as necessidades e requisitos, e identifique as variáveis relevantes para a análise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coleta de dados\n",
    "# Carregue os dados relevantes em um DataFrame ou estrutura de dados adequada usando bibliotecas como pandas.\n",
    "dados = pd.read_excel('caminho/do/arquivo.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza de dados\n",
    "# Realize a limpeza dos dados, como tratamento de valores ausentes, remoção de duplicatas ou correção de erros.\n",
    "dados = dados.dropna()\n",
    "dados = dados.drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploração de dados\n",
    "# Realize análises estatísticas, visualizações e gráficos para compreender a distribuição dos dados e identificar insights relevantes.\n",
    "descricao = dados.describe()\n",
    "plt.hist(dados['Coluna'])\n",
    "plt.xlabel('Coluna')\n",
    "plt.ylabel('Frequência')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelagem de dados\n",
    "# Prepare os dados para modelagem, como transformação de variáveis categóricas em numéricas e divisão em conjunto de treinamento e teste.\n",
    "X = dados.drop('Variavel_Resposta', axis=1)\n",
    "y = dados['Variavel_Resposta']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicação dos algoritmos de ML\n",
    "# Escolha e aplique os algoritmos de aprendizado de máquina adequados aos seus dados e objetivo, como regressão logística, árvores de decisão, etc.\n",
    "modelo = LogisticRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação de performance dos algoritmos\n",
    "# Avalie a performance do modelo usando métricas apropriadas, como acurácia, precisão, recall, etc.\n",
    "y_pred = modelo.predict(X_test)\n",
    "acuracia = accuracy_score(y_test, y_pred)\n",
    "print(\"Acurácia do modelo:\", acuracia)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publicação do modelo em Produção\n",
    "# Implante o modelo treinado em produção, integrando-o a um sistema ou disponibilizando-o para uso conforme necessário.\n",
    "# Isso pode envolver a criação de APIs, a implementação em uma plataforma ou a integração em um fluxo de trabalho existente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
